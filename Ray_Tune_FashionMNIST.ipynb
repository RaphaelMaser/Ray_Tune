{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/RaphaelMaser/Ray_Tune/blob/main/Ray_Tune_FashionMNIST.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a simple Neural Network for the FashionMNIST Dataset in PyTorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the usage of HPO using Ray Tune is demonstrated on the FashionMNIST dataset with a simple NN. First we need to install the required dependencies and import all required classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -q ray[tune]==2.2.0\n",
    "%pip install -q torch==1.13.1 torchvision==0.14.1\n",
    "%pip install -q matplotlib==3.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import random_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ray import tune, air\n",
    "from ray.air import session\n",
    "import ray\n",
    "import os\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.air import Checkpoint\n",
    "from ray.tune.schedulers import PopulationBasedTraining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards we need to download the FashionMNIST dataset and create a PyTorch dataset from that. Luckily PyTorch can automatically download the dataset if it is not found in the directory. Afterwards we create two dataloaders, one for training and one for validation. In this example we split the official train set from FashionMNIST in a two parts for that purpose. The validation set will be used to search for good hyperparameter combinations and validate the model during training. The test dataset from FashionMNIST could be used afterwards to compare the network with the standard parameters and the models optimized with HPO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Download training data from open datasets.\n",
    "data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Split the train set and create data loaders\n",
    "train_data, val_data = random_split(data, [0.8,0.2])\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used for the demonstration is a very simple fully connected network with 3 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a standard PyTorch training routine for the model. It would also be possible to use PyTorch Ignite or Lightning to avoid boilerplate code or use even other machine learning frameworks like Tensorflow or Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard PyTorch training routine\n",
    "def train_epoch(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(dataloader, model, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct*100\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train() function iterates through the epochs and executes the train_epoch() function in every step. Furthermore it uses the test() function to test the model with the data in val_dataloader and show the current accuracy. For the training we use SGD with a learning rate of 1e-4 and a weight decay of 1e-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 16.2%, Avg loss: 2.281536 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 19.1%, Avg loss: 2.262089 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 24.6%, Avg loss: 2.240741 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 29.9%, Avg loss: 2.215882 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 32.2%, Avg loss: 2.187398 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 34.0%, Avg loss: 2.154260 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 37.1%, Avg loss: 2.115401 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 39.2%, Avg loss: 2.069889 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 40.6%, Avg loss: 2.017805 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 41.6%, Avg loss: 1.959499 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Small function which iterates through the epochs\n",
    "def train(epochs):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = NeuralNetwork().to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-03, weight_decay=1e-05)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        test(val_dataloader, model, loss_fn, device)\n",
    "\n",
    "# Start the training\n",
    "train(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization (Random Search)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use Ray to do a small random hyperparameter search. \n",
    "\n",
    "The following line is not mandatory, normally Ray initializes itself if it was not initialized before, but in this case I want to set the log_to_driver argument to \"False\" to suppress the output of the trials. Otherwise the output of the different trails will be mixed in no special order because of the concurrent execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 18:07:34,998\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/plain": "RayContext(dashboard_url='', python_version='3.10.8', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '192.168.188.20', 'raylet_ip_address': '192.168.188.20', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-01-24_18-07-33_085533_320549/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-01-24_18-07-33_085533_320549/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-01-24_18-07-33_085533_320549', 'metrics_export_port': 43209, 'gcs_address': '192.168.188.20:49134', 'address': '192.168.188.20:49134', 'dashboard_agent_listen_port': 52365, 'node_id': '0f5da64135884d78719993e25b66fe5d2046f31edf5b59d54fba1eb1'})",
      "text/html": "<div>\n    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n            <g id=\"layer-1\">\n                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n            </g>\n        </svg>\n        <table>\n            <tr>\n                <td style=\"text-align: left\"><b>Python version:</b></td>\n                <td style=\"text-align: left\"><b>3.10.8</b></td>\n            </tr>\n            <tr>\n                <td style=\"text-align: left\"><b>Ray version:</b></td>\n                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n            </tr>\n            \n        </table>\n    </div>\n</div>\n"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(log_to_driver=False, ignore_reinit_error=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use Ray Tune we need to slightly change the definition of the train() function. Since Ray does not have any knowledge about the progress of the trial we need to report the training progress to Tune. For that purpose we can use the session.report() function. Furthermore the train function needs to accept a dictionary as input which contains the chosen hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune(config):\n",
    "    epochs = config[\"epochs\"]\n",
    "    lr = config[\"lr\"]\n",
    "    weight_decay = config[\"weight_decay\"]\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = NeuralNetwork().to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy = test(val_dataloader, model, loss_fn, device)\n",
    "        session.report(metrics={\"mean_accuracy\": accuracy, \"epoch\": t + 1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a compatible function for training We are almost ready to create a tuner. A tuner is used in Ray to construct and execute an HPO search. \n",
    "\n",
    "Before we define the resources which are vailable for each trial. In the standard configuration Ray assigns 1 cpu core to each trial. In our case we will assign 2 cpu cores and 1 gpu core for the trial if available. Otherwise only the cpu cores will be used. On my machine with 16 threads available this will lead to 8 concurrent trails. With tune.with_ressources() we take the train_tune() function and create a new function which respects the resource assignments.\n",
    "\n",
    "Afterwards we need to define the search space of the parameters. We are going to do HPO for the parameters \"learning rate\" and \"weight decay\". The variable \"epochs\" is also defined in the config dictionary but it is a fixed value and will therefore not be altered by Ray. The other two are defined as distributions and therefore the algorithm will sample combinations from these distributions.\n",
    "\n",
    "Now that we have defined the resources each trial can use and the search space (parameter space) which should be exploited we can define the tuner. The tuner takes the trainable function, the parameter space and a TuneConfig. TuneConfig defines how the HPO should be executed, e.g. which metric to optimize for (and whether it should be minimized or maximized) and the number of samples.\n",
    "\n",
    "Now we can start the HPO. Ray will show in real time the state of the trials and usage of resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 18:07:39,492\tWARNING worker.py:1851 -- Warning: The actor ImplicitFunc is very large (45 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "2023-01-24 18:07:39,606\tWARNING util.py:244 -- The `start_trial` operation took 0.857 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div class=\"trialProgress\">\n  <h3>Trial Progress</h3>\n  <table>\n<thead>\n<tr><th>Trial name            </th><th>date               </th><th>done  </th><th>episodes_total  </th><th style=\"text-align: right;\">  epoch</th><th>experiment_id                   </th><th>hostname          </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mean_accuracy</th><th>node_ip       </th><th style=\"text-align: right;\">   pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n</thead>\n<tbody>\n<tr><td>train_tune_99ea7_00000</td><td>2023-01-24_18-07-50</td><td>False </td><td>                </td><td style=\"text-align: right;\">      1</td><td>cda1e43b4c994c1b9647742057697900</td><td>raphael-20ujs00k00</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">        40.7833</td><td>192.168.188.20</td><td style=\"text-align: right;\">322422</td><td style=\"text-align: right;\">             8.41687</td><td style=\"text-align: right;\">           8.41687</td><td style=\"text-align: right;\">       8.41687</td><td style=\"text-align: right;\"> 1674580070</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>99ea7_00000</td><td style=\"text-align: right;\">   0.00360537</td></tr>\n</tbody>\n</table>\n</div>\n<style>\n.trialProgress {\n  display: flex;\n  flex-direction: column;\n  color: var(--jp-ui-font-color1);\n}\n.trialProgress h3 {\n  font-weight: bold;\n}\n.trialProgress td {\n  white-space: nowrap;\n}\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 18:09:06,827\tINFO tune.py:762 -- Total run time: 90.43 seconds (89.76 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# Define ressources for each trial\n",
    "resources = {\"cpu\":2, \"gpu\":1} if torch.cuda.is_available() else {\"cpu\":2}\n",
    "trainable = tune.with_resources(train_tune, resources=resources) \n",
    "\n",
    "# Define the properties of the search space\n",
    "config = {\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": tune.uniform(1e-1,1e-5),\n",
    "    \"weight_decay\": tune.uniform(1e-2,1e-6)\n",
    "}\n",
    "\n",
    "# Create the HPO tuner\n",
    "tuner = tune.Tuner(\n",
    "    trainable,\n",
    "    param_space = config,\n",
    "    tune_config = tune.TuneConfig(\n",
    "        metric = \"mean_accuracy\",\n",
    "        mode = \"max\",\n",
    "        num_samples = 4,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Start the tuner\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 10, 'lr': 0.05452556839975276, 'weight_decay': 0.0014984087014014574}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'Mean accuracy')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAA8AUlEQVR4nO3dd3ib1d3/8feR5CHv7XjG2ZuQ2BlAmSFAwixQoCUppRR+bSmjg1GgT2n7MAu0UCh9KKM0Cats0hACgRBasuzsSaZ3POW9NM7vj1t2bGfJiWTZ0vd1Xb5067Z062tfyUfH5xydo7TWCCGECB4mfxcghBCif0nwCyFEkJHgF0KIICPBL4QQQUaCXwghgozF3wV4IikpSefk5Pi7DCGEGFQKCgqqtdbJvc8PiuDPyckhPz/f32UIIcSgopQqPNJ56eoRQoggI8EvhBBBRoJfCCGCjAS/EEIEGQl+IYQIMhL8QggRZCT4hRAiyAyKefxCCBHQXE5oqYXmSmiuguZq47apEs64HazxXn05CX4hhPA2raGjuWeIHynUO49baoAj7I2izHDKNRL8QgjhF04HtNa6A/sYgd5cBU1V4Gg98nXCYiAyCSJTIHEEZM+EyGTjKyr50HFkMoTHgcn7PfIS/EII0d3BrbD5TagvORTkzVVGV8yRWuUmizuok4zbxJE9w7t7oEckQUh4v/9IvUnwCyGE0w47F8Pav0Phf8EcCnHZRlgnjYKhpx8e5p1hb40Hpfz9E/SJBL8QIng1VULBPyD/ZWgsh7ihcMH/wqnXQ0SC119Oa02ro5X69noaOhqOetv9+Olzn2ZI5BCv1iHBL4QILlpDST6sfQG2vQcuO4yYBZf8GUbNBpP5uJfocHYcO7jbG6jvqO9x23neoR1Hva5FWYgJiyEmNIaYsBgSwxNxaqcXf3j363j9ikKInrQ2Bv7qi41+464v9/22On9XaIjPgbEXw5i5EJPu72q8z94G2941Ar9sA4RGw7SbYNrN6MQR1LXXUVKzneLGYsqay7C12Y4a6m3OtqO+jEIRFRpFbGgsMWExxIbGkhaZRkxoDLFhsT1ue5+zWqyofug2UlofYbBigMnLy9OyHr8YsOxt0FDaK9h7hbyjV1CEREBspvFlTfB/H7F2GWFYu8+4n5FrvAmMvQSSx/i3tpNVVwz5L+EoeJVyez0lScMpHn4GJbFplLRWUtxYTEljCU32ph5Ps1qsHoV1j++FxRAVEoXZg78a+oNSqkBrnXfYeQl+IY7heK31+mJjxkdvUUMOBXtcFsRmHbofmzUwBwS1hqpdxiDnzn9D2XrjfOKoQ28CGbk+mV7oLc32ZiPIG4opLlpJSeFKipvLKLZYKA+x0L3TJMQUQkZUBlnRWWRGZxq3UcZtRnQGVovVbz+Ht0jwC3EkR2ut17nvN5QepbXeK8i7jjONbhJLmH9+Hm+qL4VdS4w3ggP/AZcDolKNrqCxl8Cws8AS2q8lubSLqpYqI9ybSrpa6yWNxrGt3dbj8bEuTVZYApkpk8hKGNMj5JOtyQOmZe4rEvxCgDEXe/cyI9AKVxkfvulBQfSh1ro9Jp326DTaopNpj0yiPSKBNksY7a4O2hxttDvbaXO20e5oN457nWtzGve7H3c+pvPYqZ2YlRmLyYJZmTGbzF33Tcp02PcsytL1mN73Ox9nUqajPudIr9P5nO7nO49NyoTZ3oq5dAOmotVYSvIxOVoxh0RizpqJafhZWIZ+C1NYTI/ndK+/6/rdrn20vuw2RxtlTWWHhXtxYzGlTaW0O9u7HmtSJtIi08gMSySz2UZW5TdktTaRGTeCzNybiDnlewNi3ry/SPCL4FWzF3Z9bHwVrUJrJ8sS0licmEqrJZQ2k5l2k6INTbvL2SPUT3RGhUIRbgknzBxGmDms6zjcHE6YJazHsVmZcWkXTpcTh3bgdDlxauPY5XIZxy4HTu3s8b2u497f63XfqZ24tMvLv9STZ1KmHm8MnW8GDR0NPR5ntVjJis7q0RWTGZ1JVmQ6aeXbCcl/CfYuB1MITPg2TL8FMvMGXleaHxwt+GVWjwg8LqcxXW/XEiPsq3cZ51MnsnfmTTzSXsQa23Yywq2kRKRgNYcRf4RADjeH9wjtIwV452O6jt23IaaQfpmd4SmXdh3zzcHusnc9pvPN5khvHj3OuZy4XA6cVbtwlubjLFuPs6UaFwpnfA7OIRNxpk7AGRF/+HM7n68Pf61Ea2KPkE8IT+j5u2yphY2LYN1PwXYAotPg3Acg9waISvHb73gwkeAXgaGjGfatMML+m0+MAVeTBXK+BdNuomnYWTxfuJjXdryGNcTK/TPu5zujvxPwfbydOlvXIaYQ7188ZzZMwxgcrtxhDAzvXAzr3jC+nzTGGBwedwmkTTnxweGDW4ypmJv/ZayDM/QMOP9BY7zB7IOfK4BJV48YvBor4JulRtjvW2EMwobFGh/CGTMHRs1Gh8WweN9inip4iprWGq4cdSW3T72dhHDvfypT9FJXbPzFtfMjOPBf0E6IToexc403gqHfOv7gsNMOOz4yllIo+hosVmO1yuk3w5BJ/fNzDGLSxy8Gv84WZWcXTqn730RcNoy52Aj7oad3tf521u7kkTWPsL5yPZOSJnHfjPuYmDTRjz9AEOscVN+5GPYsB3uL8SY9+gKjxT5yFoRFH3p8Y4WxlELBK8ZSCvE5MO1mmHK915coDmQS/GJwctqhaBXsXGIEfl2hcT4j1wj6MXMhZXyPgbz69nqe3fAsb33zFrGhsdyZeydXjLwCkxq488+Dir3V+Att52LjDbylBsxhMPwc46+14jWw7X1jKYWR5xuDtSPP92gpBdGTDO6KwaOtHvZ8ZoTC7mXG/c5gOPMXMPoiY8plLy7t4r3d7/H0+qep76jn2jHXcuuptxIbFtv/P4M4uhCr+017jjEQX7T60LjA7k+M9eqn/cj4Shrp72oDkgS/GBjqimCXu7/+wH+M1l5EEoy91AiIEedCaORRn76lagsPr3mYrTVbmZoylftm3MeYhEG+1EAwMJkh5wzj68KHjCUjolIhLMrflQU0CX7hH1oba8N0zq+v2GKcTxoNp/3U6MLJnHbcP+9r22p5ev3TvLv7XZKsSTxy5iNcPOziATWVUnhIKWNHKuFzPg1+pdTPgR9hbFuzBbgRSAPeABKBAmC+1rrDl3UIN6fDmAbnchh/Yve47X18lPvag8ccdr/XudZaY4CvsRyUCbJmGmugj57j8Z/2DpeDf33zL/6y4S+02lu5YfwN/Hjyj4kKlZaiEMfjs+BXSmUAtwPjtdatSqm3gOuAucCftNZvKKX+BtwEPO+rOgTGImNfPwNrXwR7s39qUCZjXr0yGx+hzznTaNWPugAiE/t0qfUV63l4zcPssu1iRtoMfj3914yIk5aiEJ7ydVePBbAqpexABFAOnAd8z/39V4EHkeD3ja7A/7sxk2LilZB2qhHAJovRjdJ1fLT7x3uMB9dRZq+s6FjVUsVTBU+xeN9ihkQO4cmzn2T20NnSrSNEH/ks+LXWpUqpJ4AioBVYhtG1U6d11xY0JUDGkZ6vlLoFuAUgOzvbV2UGpt6BP+lqOOtuSB7t78pOiN1l57Udr/H8pufpcHZw86Sb+dGkHxEREuHv0oQYlHzZ1RMPXA4MA+qAfwEXefp8rfULwAtgzOP3QYmBJ8ACH2B1+WoeWfMI++r3cWbGmdw7/V6yY6QhIMTJ8GVXz/nAfq11FYBS6l3gDCBOKWVxt/ozgVIf1hAcuge+ow0mXg1n3TWoA7+8qZwn8p9gWeEyMqIy+Mt5f+HszLOlW0cIL/Bl8BcBM5VSERhdPbOAfOAL4GqMmT03AB/4sIbAFoCB3+Hs4NVtr/L3LX/HpV3ceuqt3DjxRsLMAbCxiRADhC/7+Ncopd4G1gMOYANG182/gTeUUv/rPveSr2oIWAEY+AArS1by2NrHKGos4vzs8/nVtF+REXXEISAhAop2OnHabDiqq3FU1+Csqe46Tvp/t2COi/Pq6/l0Vo/W+rfAb3ud3gdM9+XrBqwADfzixmIeX/s4K0pWkBOTw/+d/3+cnnG6v8sS4qR0hXlNDY7qapzuIDfuV+HsOq7GabOB6/DNclR4OHFXfntwBb/wkgAN/FZHKy9vfZmXt7yM2WTm57k/Z/64+YTI2upigNIul7tl3rNV7qiudt83jh01NThra48c5mFhWJKSMCclEpKZiXXyZCxJiZiTkrAkJmFJSjS+n5iEKTLCJ+NaEvwDWYAGvtaaz4s+5/F1j1PWXMacYXP4Ze4vSY1M9XdpQtBRUkLTii+xl5f1aJU7aqpx1trAefh2nCosDEuiEd4hGRlYTzkFszvAe4R5UhKmyEi/T1KQ4B+IAiDw7S47tjYbtjYbtW211LbVdh1vrtrMmoNrGBk3kpcvfJlpQ6b5u1wR5OwVFTR8/DENH39M26bNAKjQUHd4JxOSloZ10sQjtMqNW1NUlN/DvC8k+AeSpioj8Ne9aAT+pO8YgZ80yt+VYXfZqWurOyzEa9tqsbXbqG01bm1tNmraamjsaDzidczKTHJEMvdMu4frxl6HxST/BIV/OGpqaPjkExqWLKG1YD1oTdj4cST/8hfEXHQRIZmZgyrM+0L+1w0Efgh8h8tBXXsdNa01PYK7e7B3D/eGjoYjXsekTMSHxRMfHk9CeAJjE8YSH27cTwxP7DofHx5PQlgCMWExsiGK8BtnXR0Nn35Kw5IltKxZCy4XoSNHkHTbz4iZM4ewYcP8XWK/kODvBzWtNRQ3FmN32XFqJ06XE6d24mipxbHjQ5x7l+NwOXCOnIFz1AU4IhJxVK3FWbHKeLx2Gs91P8/pcuLQDuM5nddyOY5463QZx52Pr2+vP26Qx4XFkRCeQEJ4AmMSxvQI7gRrAvFh8V3flyAXA52zsZHG5ctp+Phjmv/7NTgchAzNJvH/3ULMnDmEjx48XajeIsHvY3tse/j+x9+n0X7krg8AEmOM27a9sOXY69VZTBYsyoLZZMZismBW5sPvd781Hfq+1WJlSOQQI7itCSSEJXS1yDvDPTYsVoJcDHqulhaaVqygfskSmld+he7owJKeRuIPbiB6zhzCx48P2G4cT0jw+1BVSxU/Xf5Twi3hPHzmw1jt7Zi3vY9l52IsjnbMI2djzr0RS8LwrpA+LLi73Zplz1EhjsrV3k7TypU0fvwxjV+sQLe2YklOJu66a4mdO5fwyZODOuy7k+D3kRZ7C7cuv5W69jr+cdafGL9j6YActBViMNMdHTR9/bUR9p8tx9XcjDk+ntgrLidmzhwicnNRZmkw9SbB7wMOl4O7Vt7FLtsu/nLKHYx/fT602iTwhfAC7XDQsnYt9UuW0PjpZ7jq6zHFxBB90YXEzJ1L5IwZKMvgirbGNjulda2U2lq7bkvcty/MzyUlJtyrrze4fjuDgNaaR9c+ysqSlfxm+NWc9e8HICoZfvBvSBnn7/KEGJS0y0VrQYEx1/6TZThrajBFRhI16zxi5swh6owzUKGh/i7ziLTWVDd1UFrXSlm3cC/pCvkWGtocPZ4TajaRHhdORryVVvvhHxg7WRL8XvaPbf/gzV1vcmPKaVzzxTNG2F//DkTLp1KF6AutNW2bN9OwZAkNSz/BUVGBCg8n6txzjLA/6yxM4d5tCZ8Ih9PFwYa2Hq310rqex+2Onks3RIdZyIi3khFnZVpOPBlxVtLjrGTEW8mMs5IUFYbJ5LvxCAl+L1p6YClPFTzFRVEjuHPNm8a+ste9BuEx/i5NiKOyl5bSkp+Po9Zm9IdbzCizBWWxoCxmMHfemt3nLMbj3OeVxXLo2GwGTx9zhIFWrTXtO3YYLfslH2MvLUWFhBB51lnE3H0X0eecgykysl9/P60dzl5B3kJZ3aGgP9jQhtPVc6+opKhQMuKsjE2LZta4FDLirGTER7hvrcRa/bselQS/l2yo3MD9X93PlJAE/nfrF5jGXw5X/h0sso68GDi01tiLi2lZt46WtetoWbcOe1mZf4oxd3sTcL+p4HLhrK8Hi4XI008j6bafET1rFuboaJ+X02Z3sqW0ng1FNjaV1FNc20KprZWa5o6eZZsUQ2KMbpgZwxK6Wu4Z8e5We5yV8JCBPaAswe8FhQ2F3P757aRh4pk9mwnL+xHMedzYdFwIP9Ja07H/gBH07i9HRQUA5oQEIvLySLjxRiKmTyMkIwMcDrTTiXY4wWE/dOx0oB2OQ8fu89phh85jp8N4fuex04m2Ow4dO5xoh8N9rd6Pd3adD58wgegLZmOJj/fp76XE1sr6IhsbiupYX2Rje1kDDnfLPTPeyrCkSCakx3SFekZcBBnxVlKjw7CYB/dnXST4T1JtWy0/+fTHqPZGni8uJu7sXxszd2S+sPADrTUde/bQ3Bn0+fk4q6oBsCQnEzFtGhHTpxGRl0foiBFBM6+9pcPB5pL6rqDfUFRHdVM7ANYQM5OzYrn5rOFMzY5nSnYcSVGB/Ze6BP9JaHO0cdunP6GysYSXDlaSNedJyP2Bv8sSQUS7XLR/801Xt01Lfr6xqQdgSUsj8rTTiJg2jchp0wgZOjQogl5rTWFNS4/W/M6DjV398MOSIjlrdBJTsuOZmh3HmNToQd+C7ysJ/hPk0i7u+/xOttRs56nqOiZf/hKMu8TfZYkAp51O2nbsPNR1U1CAq74egJCMDKLOPpuI6dO7um6CIeib2h1sLq471JovrqPW3S8fFWZhclYsPz1nBFOy45iSFU985MCc9tmfJPhP0FMr7+fT8v9yV0Mr51/9BuSc4e+SRADSdjtt27YZXTf5+bQWrMfV1ARA6NChxFww2+i+ycsjJD3dz9X6nsul2VfdzIYiG+uL6thQZOObikY6J9WMTIli1tgUpg41umxGpURj9uG0yMFKgv8EvP71w7x6YDHfbXUy/5r3YchEf5ckAoSro4O2LVsOzbrZuBHd0gJA6IgRxFxysTvopxGSmuLnan2voc3OpuI61hcaLfqNxXXUt9oBiA63cGpWHBdOGNLVmo+NkG07PSHB30crVj3Bo9+8xjkOE/dcsxiVMNzfJYlBzNXeTuvGTV1dN60bN6LbjUHHsNGjifv2t42gn5aHJTHRz9X6lsul2VPVZLTmC+vYUGxjd2UTWhtzJUanRDNn4pCuAdgRyVE+/ZBTIJPg74Nt/3mcu3e/yjhCeew7H2KOzfJ3SWKQ0Q6H0XWzajXNa1bTun6DEfRKETZuLPHXXUvEtGlYc3N9Op1xIKhvsbO+uHOWjY2NRXU0thtLF8RaQ5iSHcclp6QzNTueU7JiiQmX1ry3SPB7QmtKP/8dtx54iwRLGM9e8QEREvrCA1pr2r/ZTcua1TSvWk3LunVdffRhY8YQf911RMyYQUReLuaYwP2Et9Ol+aaisWuWzYYiG3urmgEwKRgzJIZLT01nSlYcU4fGMzzJ/xuSBzIJ/uNxuahf8kt+Wv4xHaHhvHzJGyTFZvu7KjGAdRQX07xqFS2r19C8Zg3OmhoAQoZmG6tHnjaTiBkzsCQk+LlS36lt7mBDt+mUm4rraO4wFhtLiAxlanYcV07NZEp2HKdkxhEVJlHUn+S3fSyOdjrevYWf135NkdXKCxe8wPDEMf6uSgwwjqoqmlevoXm1Efb20lLA+MBU5BmnEzljJpEzZxifjA1ADqeLnQcbewT9gRpjQNpsUoxLi+aqXCPkp2bHk50QIa15P5PgP5r2RvQb3+O3TdtYFxXJI2c+zLS06f6uSgwAzoYGWtatM/rpV6+iY89eAEwxMUTOmE7CD28kcuZMQocPD8iAq2ps7zGdcnNJfdfSwUlRYUzNjuO66dlMyTJa89ZQWbpkoJHgP5KmSlh0Nc+2FbI4LobbptzGJcPlw1nBytXaSsv69bSsXk3z6jW0bdsGLhfKaiUiN5e4K64gYuZphI8bG3C7PdmdLnaUN7C+0B30xTaKa1sBCDErxqfHcu20LGPefFYcmfHWgHyzCzQS/L3V7ocF3+Y9Vx0vJMRw5agruXnSzf6uSvQjbbfTumWr0XWzarUxxdJuB4sF6+TJJP3kJ0TOnEH45MmYBujmHyeqoqHtsNZ851ryqTFhTM2O5/szc5iSHcfEjNgBvwqlODIJ/u7KN8PCq/ja4uL3iXGcnjaDB2Y+IC2YAKddLtp37erqp29dl4+rpeXQFMv5840B2alT+30teF/qnDe/Zn8ta/fXsr7QRmmd0ZoPNZuYmBHDvJlDu+bNp8dZ/Vyx8BYJ/k77V8Lr32NXZCy/SIpkeHQWT579JCEmmTsciBw2G42ffGJMsVyzBmddHQChw4YRc/llRM48jYjp0wJqLr3D6WJ7eQNr99eyZn8t6w7UUtdifAp2SEw4uTnx/PBbw5iaHcf49BjCLNKaD1QS/ADb3od3b6YiMYefJkYRaTLx3KzniAqN8ndlwsvaduygduFCGj5ajO7owDJkCFHnnEPEzBlEzpxJyJAh/i7Ra9rsTjaX1LN2fw1rD9goOFDbNaUyJzGCC8anMi0ngRnDEslKkL75YCLBv/bvsOQumrKmcWtiFM0t5bw6+1WGRAZOAAQ77XDQuPxzbAsW0JKfj7Jaib3qSuKv+y5ho0cFTOA1tztYX2TratFvLK6jw90/PyY1miunZjJ9WALThyWQGuP/vWqF/wRv8GsNXzwMKx/HPuoifpUUw56KdTw36znGJMhc/UDgrKuj7u23qX3tNRxl5YRkZJBy993EXXUl5thYf5d30upaOlh3wGa06PfXsrWsAadLYzYpJqbHcMNpQ5mWk8C0nARZilj0EJzB73TAkl9CwT/Qp17PQ8nJ/HfPuzx42oOckSHLKw92bbu+wbZwIfUffYRuayNi5kyG3H8/UeecM6inW1Y2tHX1za/dX8vOg42AMRB7alYcPzl7BNOHJTB1aLx8ElYc03H/dSilErXWNf1RTL+wt8E7N8HOxXDmL3kpOY13NjzDzZNu5qrRV/m7OnGCtNNJ04oV1C5YSMvq1aiwMGIvu4z4efMIHzPa3+X1WeeesMaMG6NF3/lp2IhQM7lD47l4UhrThyUwOStOplWKPvGkWbBaKbUReAX4WGutfVuSD7XWwevfhaJVcNFj/Dsli6e/upe5w+Zy25Tb/F2dOAHOhgbq3n4H26JF2EtLsaSlkfzLXxB39dWDakaO1po9lYemVq7dX8vBhjbAWKlyWk4C188YyvRhCYxPjyEkyLYKFN7lSfCPBs4Hfgg8o5R6C/iH1vqbYz1JKTUGeLPbqeHA/wD/dJ/PAQ4A12itbX2uvK8aymHhVVD9DVz1IvnJOfzm01vITc3lD2f8IWAG+IJF+9691C5cSP37H6BbW4nIyyPl7ruJnnUeyjI4ujnqWjpYuvUgX+yqZN0BW9d2gcnRYcxwD8JOH5bA6JRoWXdeeJXqSwNeKXUusBCIBDYB92qtV3nwPDNQCswAbgVqtdaPKqXuBeK11vcc6/l5eXk6Pz/f4zoPU70bFlwJrbVw7UL2JQ1l/pL5JIQnsHDuQmLDBv9AXzDQLhdNK1di++cCmr/+GhUaSswll5Aw73rCx4/3d3keaW538NmOCj7cWMbK3VXYnZqMOCszhyd2hf3QRFnETHiHUqpAa53X+7xHffzAPGA+UAHcBnwInAr8CxjmwevPAvZqrQuVUpcD57jPvwqsAI4Z/CelpAAWXQ3KBD9YTHV8Fj9dMg+LycLz5z8voT8IOJuaqH/3XWoXLsJeVIQlNZXkO+8k7prvDIqljdsdTr7cVcWHm8r4bEcFbXYXabHh/OD0HC6bnMHEjBgJetGvPPmbeBWwALhCa13S7Xy+UupvHr7OdcDr7uNUrXW5+/ggkHqkJyilbgFuAcjOPsH17/d8Bm9+HyKTYP57tMamc/snN1HTWsMrF71CZnTmiV1X9Iv2/fuxLXqN+nffxdXSgnXKFFLuvIPo2bNRIQP7E9UOp4tV+2r4cGMZS7cdpLHNQUJkKFfnZnLZ5AzyhsZL943wm+N29Sil1MkM6CqlQoEyYILWukIpVae1juv2fZvW+pijcCfU1aO10dJvrIB57+CMTOLnK37OiuIV/PncP3Ne9nl9/2GEz2mXi+b//pfaBQtoXvkVhIQQO3cO8fPmY500sDe111qzvsjGhxvL+PeWcqqbOogKs3DBhFQum5zOGSOTZFBW9KsT7uoBlimlvqO1rnNfKB54Q2t9oYevPQdYr7WucN+vUEqlaa3LlVJpQKWH1+kbpeDqVwAN4bH8ce2jfFH8BfdOv1dCfwByNjVT//772BYupOPAAczJSSTd9jPir7kGS3Kyv8s7Kq0128sb+HBTGYs3lVNa10qYxcSscSlcNjmdc8akyFRLMeB4EvzJnaEPoLW2KaVS+vAa3+VQNw8Y4wM3AI+6bz/ow7X6JtzYw3Th9oUs2rGIeePmcf246332cqLvOoqKsC1aRN077+JqaiJ80iTS//g4MRdeiBrASx7vr27mw41lfLiplL1VzZhNijNHJfHLC0Yze3wq0bIxuBjAPAl+p1IqW2tdBKCUGgp41PWjlIoEZgP/r9vpR4G3lFI3AYXANX0ruW+WFy7n8XWPMyt7Fr/K+5UvX0p4SGtNy6pV1P5zAU1ffglmMzEXXkjC9+djnTzZ3+UdVVldK//eXM6Hm8rYUlqPUjAtJ4EbzxjG3ElpJMiyCGKQ8CT47wf+o5T6ElDAmbgHXY9Ha90MJPY6V4Mxy8fnNldt5p6v7mFS0iQeOfMRzCb5k9tfHLW1tBQU0JpfQNNXX9Gxbx/mhASSfvJj4q69jpDUvvwR2X9qmtpZsvUgH20sY+2BWgBOyYzlgYvHcfEpaaTFyhr1YvA5bvBrrZcqpaYCM92n7tRaV/u2rJOntebJ/CdJtibzzHnPYLXIf9D+ZC8tpSU/n5b8AloKCujYtw8AFRqKdfJkEm++mZi5czCFhfm50sM1ttlZtq2CDzeV8Z891ThdmpEpUfxi9mgunZzOsKTA2YxFBCdPP+LoxBiEDQfGK6XQWq/0XVknTynF0+c+TWNHI4nWxOM/QZww7XLRsXcvLQUFXUHvKDdm7Jqio7FOnULsFVcQkZdL+MSJA3K7wja7k893VvLhxjI+31VJh8NFRpyVm88czmWT0xmXFi1z7UXA8OQDXD8C7gAygY0YLf9VwICfGhMXHkdceJy/ywg42m6nbfv2rpBvLSjAWV8PgCU5GWteLhE33UREXi5ho0YN2BUx7U4X/9lTzUcby1i2vYKmdgdJUWF8b3o2l05OZ2p2nIS9CEietPjvAKYBq7XW5yqlxgIP+7YsMZC4Wlpo3bTpUNBv2oRuNfZmDRmaTdSsWUTk5hKRl0tIdvaADcvqpna2lNaztaSeLaX1rDtQi63FTnS4hbmThnDZ5AxmDk/AInPtRYDzJPjbtNZtSimUUmFa653uBdhEgHLYbLSuX98V9G3bt4PDYWw+PnYscVddRUReLhG5uQN2jn1lYxvbShvYUmqE/NbSesrr27q+PywpknPGpDBn4hDOHpMs+8uKoOJJ8JcopeKA94FPlVI2jGmYIkDYy8q69c/n07FnLwAqJITwU04h8Yc/JCIvF+uUKZijo/1c7eEqG9p6BPyW0noqGtoB43N8w5IimT4sgUkZsUxIj2VCRgwxMs9eBDFPZvV82334oFLqCyAWWOrTqoTPaK2NgVh3a76lIB9HmXsgNioK65QpxF5yqTEQO2nSgJp1o7WmoqG9K+S3uW8rGw+F/PCkSE4bnsjEjFgj6DNiZTcqIXo55v8I93LK27TWYwG01l/2S1XC69p376b6+edp/noVzro6AMxJSUbf/A9uNAZix4wZMAOxWmsONrSxpeRQK35LaQPVTUbImxSMSI7iWyOTjJDPjGV8WgyREvJCHNcx/5dorZ1KqV3dP7krBhdHbS1Vf/kLdW/9C1NkJNGzZnX1z4cMHTogBmK11pTV9wz5bWX1VDcZG5OYFIxKieas0UlMcrfkx6fHEBEqIS/EifDkf048sE0ptRZo7jyptb7MZ1WJk+bq6MC2YAHVz/8NV2sr8dddR9LPbh0Q2xGW1rWypaSuqxW/tbS+a/cps0kxKiWKc8akMCkjlokZRkveGjow/hIRIhB4Evy/8XkVwmu01jQu+5TKJ57AXlxM1Nlnk3LP3YQNH+63mpwuzcZiG59ur+SzHRXsqWwCwGJSjEqN5vxxKV398ePTYmQ1SyF8zJPBXenXHyRat26j8tFHacnPJ2zUKLJeepGoM87wSy3N7Q6+2l3N8h0VfL6zkprmDiwmxczhiXxvejZTh8Yzdki0hLwQfuDJJ3cbObQaZygQAjRrrWN8WZjwnL2igqo//Zn6Dz7AHB/PkAcfJO7qq/p90/GKhjY+21HBZ9sr+O/eGjocLmLCLZw7NoXzx6Vy9phkmUYpxADgSYu/a+K2MkYCL+fQgm3Cj1ytrdS89DI1L70EDgeJP7qJxFtu6be59lprdpQ3GmG/o4LNJcayDdkJEcybMZTzx6cwLSdBdp0SYoDpU5PQvQXj+0qp3wL3+qYkcTza5aLho4+ofOpPOCoqiL7oIlJ+9UtCM32/h3CHw8XqfTV8tqOC5TsqKa1rRSmYkhXH3ReNYfa4VEamRA2I2UJCiCPzpKvnym53TUAe0HaUhwsfaykooOKRR2nbupXwiRPJeOpJInJzffqadS0dfLGrks+2V/LlN1U0tTsIDzFx5qhk7pg1inPHppAcPXA+6CWEODZPWvyXdjt2AAcwuntEP+ooKaHyiSdpXLoUS2oq6Y89Ssyll6JMvulG2V/dzPIdFXy6vYL8QhtOlyY5OoxLJ6dx/rhUzhiZJAOzQgxSnvTx39gfhYgjczY1UfO3v1H76j/BYiHptp+ReOONmCIivPs6Ls2GIhufugdn91YZH9kYOySan54zgvPHpTIpIxaTSbpwhBjsPOnqeRW4o3PDdaVUPPCk1vqHPq4tqGmHg7q336HqmWdw1tYSe8UVJP/8TkJSU732Gp1TLj9zT7ms7Tblcv7Mocwal0pWgnffYIQQ/udJV88pnaEPoLW2KaWm+K4k0fSf/1L52GO0796NNS+X1BdewDpxgleufbC+jeU7ZcqlEMHMk+A3KaXitdY2AKVUgofPE33UvncvFY8/TvOXKwnJyiLj6aeJvmC2V2bIFBTaeOjf21lfVAcYUy7nzxzK+eNSycuJlymXQgQRTwL8SWCVUupf7vvfAR7yXUnBx2GzUf3sc9jeeAOT1UrKXXcRP3+eV/amrW+18/jSnby2toghMeEy5VII4dHg7j+VUvkc2mP3Sq31dt+WFRx0Rwe1r71G9V+fx9XURNy115B8221YEhJO/tpas3hzOb9fvJ2apnZ+eMYwfj57tKxNL4TwaHB3Jsaa/M+678copWZordf4vLoApbWm6fPPqXz8j3QUFhL5rW+Res/dhI0a5ZXrF9e28MD7W/nymyomZcTyyg+mMTEj1ivXFkIMfp40/54Hpna733SEc8JDbTt2UPHoY7SsWUPoiBFk/f0Fos480yvXtjtdvPjVfp5e/g1mpfjtpeP5/mk5mGUKphCiG0+CX7mXagBAa+1SSkl/QR/ZKyupevpp6t99D3NsLKn/8xvir7nGawupFRTauP+9Lew82MiFE1J58LIJpMVavXJtIURg8SR19imlbsdo5QP8FNjnu5ICT+2ChVT+6U9ou52EH/yApJ/8GHOMdxY3rW+188dPdrJojTF4+8L8XC6YMMQr1xZCBCZPgv/HwDPAAxjLMy8HbvFlUYGkccUKKh56iMizzmTI/fcTOnSoV66rtebfW8r53UcyeCuE6BtPZvVUAtf1Qy0Bx1FdTfn9DxA2ZgyZzz7rlemZYAze/uaDrazYJYO3Qoi+82RWTzhwEzABCO88L0s2HJvWmrL778fV1ETGP17xSujbnS5e+s9+/vyZDN4KIU6cJ/0CC4CdwIXA74HrgR2+LCoQ2F57jeYvV5L6wANemaYpg7dCCG/xJPhHaq2/o5S6XGv9qlLqNeArXxc2mLXv2UPl438k8qwzib/+eyd1LRm8FUJ4myfBb3ff1imlJgIHgRTflTS4uTo6KP3VXZgiI0l/6KETXhah9+DtjacP4xcXyOCtEOLkeZIiL7iXYn4A+BCIAn7j06oGsao//Zn2nTvJfP6vWJKTT+ga3QdvJ2bE8PIN05iUKYO3Qgjv8GRWz4vuw5XAcN+WM7g1f/01ta+8Qtx3ryP63HP7/Pzeg7f/c8l4vn/aUCyycqYQwot82m+glIoDXgQmYnwG4IfALuBNIAdjG8drOpd8HswcNhtl9/6a0OHDSb377j4/f32RjfveNQZvLxhvDN6mx8ngrRDC+3zdYfw0sFRrfbVSKhSIAO4DlmutH1VK3QvcC9zj4zp8SmvNwd8+iMNmY9jfnsdk9Tywew/e/t/8XC6UwVshhA/5LPiVUrHAWcAPALTWHUCHUupy4Bz3w14FVjDIg7/+3XdpXLaMlLt+Rfj48R49RwZvhRD+4lHKKKVOx+ia6Xq81vqfx3naMKAKeEUpNRkoAO4AUrXW5e7HHASOuImsUuoW3EtDZGdne1KmX3QcOMDBhx4mYuZMEm70bF96GbwVQviTJ5/cXQCMADYCTvdpDRwv+C0YSzffprVeo5R6GqNbp4vWWiul9JGerLV+AXgBIC8v74iP8Tdtt1N69z2okBDSH30EZTr2IKwM3gohBgJPWvx5wPjuSzN7qAQo6bZhy9sYwV+hlErTWpcrpdKAyj5ed8Co+utfadu8mYw//4mQIcful5fBWyHEQOFJ8G8FhgDlx3tgd1rrg0qpYqXUGK31LmAWsN39dQPwqPv2g76VPDC0FBRQ838vEHvllcRcdNExH/vEJ7t4bsUeGbwVQgwIngR/ErBdKbUWaO88qbW+zIPn3gYscs/o2QfcCJiAt5RSNwGFwDV9rtrPnI2NlN11NyGZmaTed98xH1tY08yzX+zh0snpPHLlJBm8FUL4nScp9OCJXlxrvRGjq6i3WSd6zYHg4O//gL2igpxFCzFHRR7zsYvWFGE2KR64eJyEvhBiQPDkk7tf9kchg0X9R4tp+Ogjkm6/Deuppx7zsW12J2/lF3PhhFRSY8KP+VghhOgvx51OopSaqZRap5RqUkp1KKWcSqmG/ihuoOkoKeXg736HdcoUkm45/iZk/95cTl2LnXkzvbPrlhBCeIMn8wifBb4L7AaswI+A53xZ1ECknU7K7rkHtCb9j497tEn6gtWFjEiO5LThif1QoRBCeMajCeRa6z2AWWvt1Fq/Ahx7GksAqvn732ktKGDI//yG0MzM4z5+S0k9G4vrmDdz6AkvzSyEEL7gyWhji3tWzkal1OMY0zqD6hNHrZs3U/Xsc8TMnUvMZZ5MZoKFqwuxhpi5curx3ySEEKI/eRLg892P+xnQDGQBV/myqIHE1dxM6V13YUlJZsiDv/Wo9V7faueDTaVcMSWdWGtIP1QphBCe82RWT6FSygqkaa1/1w81DSgHH3kEe1Ex2a/+A3NMjEfPeaeghDa7SwZ1hRADkiezei7FWKdnqfv+qUqpD31c14DQsGwZ9W+/Q+LNNxM5fbpHz9Fas3B1IVOy45iQLguvCSEGHk+6eh4EpgN10PWhrGE+q2iAsFdUcPA3/0P4xIkk/+xWj5/39d4a9lU3M19a+0KIAcqT4Ldrret7nRuQq2V6i3a5KLv3XlwdHcbUzdBQj5+7cHUh8REhzJ2U5sMKhRDixHkS/NuUUt8DzEqpUUqpvwBf+7guv6p99Z+0rFpN6q/vJWyY53/cHKxvY9n2Cq6ZlkV4iNmHFQohxInzJPhvAyZgLND2OtAA3OnDmvyqbccOqp56iqjzZxH3ne/06bmvry3CpTXXT5duHiHEwOXJrJ4W4H73V0BztbVR+qu7MMfFkfaHP/Tpg1d2p4vX1xZx9uhkshMjfFilEEKcnKMG//Fm7ni4LPOgUvnHJ+jYu5esF1/EEh/fp+d+ur2CysZ2HpFBXSHEAHesFv9pQDFG984aIKDXHWj68ktsixaRcMP3ifrWGX1+/sLVhWTEWTlnTIoPqhNCCO85Vh//EOA+YCLwNDAbqNZafxloSzU7amoou+9+wkaPJvkXv+jz8/dUNvL13hqun5mN2RTQ749CiABw1OB3L8i2VGt9AzAT2AOsUEr9rN+q6wdaa8rvux9XYyPpT/wRU1hYn6+xcHURIWbFNXlZPqhQCCG865iDu0qpMOBijGWZc4BngPd8X1b/sb3+Ok1ffknqffcRPnp0n5/f0uHgnYIS5k5KIymq728aQgjR3441uPtPjG6eJcDvtNZb+62qftK+dy+Vjz1O5JlnEj9/3gld44ONZTS2O+STukKIQeNYLf55GKtx3gHc3m1qowK01tqzFcsGKFdHB6W/ugtTRATpDz90Qmvma61ZsKqQsUOiyR3at1lAQgjhL0cNfq11QK+5X/Xnp2nfsYPMv/4VS3LyCV1jQ3Ed28sbeOjbE2WzFSHEoBHQ4X40zatWUfvyy8Rddy3R5517wtdZuKqQqDALV5ya4cXqhBDCt4Iu+B02G2X3/prQYcNIveeeE75ObXMHizeXc+XUDCLDPNnITAghBoagSiytNQd/+yCO2lpy/vocJqv1hK/1r/xiOpyy2YoQYvAJqhZ//bvv0bhsGSl33I51woQTvo7LpVm4ppAZwxIYnRrtxQqFEML3gib4OwoLOfjQQ0RMn07CjTee1LW+3F1FcW2rtPaFEINSUAS/ttspvetulMVC+mOPoswnt1b+wlWFJEWFceGEIV6qUAgh+k9QBH/188/Ttnkzab//HSFpJ7czVnFtC5/vquS707MItQTFr08IEWACPrlaCgqo/tv/EXvFFcRcdNFJX+/1tUUo4LvTs0++OCGE8IOADn5nYyNld91NSEYGqQ+c/D4y7Q4nb64r5vxxqaTHnfiMICGE8KeAns558A9/wF5RwdCFCzBHRZ309ZZuPUhNc4cM6gohBrWADX6tNZEzTyN89GgipkzxyjUXrCokJzGCb41M8sr1hBDCHwI2+JVSxF35ba9db0d5A/mFNh64eBwm2WxFCDGIBXQfvzctXF1ImMXE1bmZ/i5FCCFOigS/Bxrb7Ly3oZTLJqcTFxHq73KEEOKkSPB74L0NpbR0OGVQVwgREHzax6+UOgA0Ak7AobXOU0olAG9ibOV4ALhGa23zZR0no3OzlVMyY5mcFefvcoQQ4qT1R4v/XK31qVrrPPf9e4HlWutRwHL3/QFr7f5adlc2SWtfCBEw/NHVcznwqvv4VeAKP9TgsQWrC4m1hnDpKen+LkUIIbzC18GvgWVKqQKl1C3uc6la63L38UEg9UhPVErdopTKV0rlV1VV+bjMI6tsbGPp1oNcnZuJNfTkFnYTQoiBwtfz+L+ltS5VSqUAnyqldnb/ptZaK6X0kZ6otX4BeAEgLy/viI/xtTfXFuNwaa6fIevyCCECh09b/FrrUvdtJfAeMB2oUEqlAbhvK31Zw4lyOF28traIM0clMTz55Jd7EEKIgcJnwa+UilRKRXceAxcAW4EPgRvcD7sB+MBXNZyMz3dWUl7fJoO6QoiA48uunlTgPaVU5+u8prVeqpRaB7yllLoJKASu8WENJ2zB6kLSYsOZNTbF36UIIYRX+Sz4tdb7gMlHOF8DzPLV63rD/upmvtpdzS9mj8Zils+4CSECi6TaESxaXYjFpLhuWpa/SxFCCK+T4O+lze7kXwUlXDhxCCkx4f4uRwghvE6Cv5ePNpVR32pnvgzqCiEClAR/LwtXFzIqJYoZwxL8XYoQQviEBH83m4rr2FRSz7yZQ3HPRhJCiIAjwd/NwtWFRISa+fbUDH+XIoQQPiPB71bfYufDTWVcMSWDmPAQf5cjhBA+I8Hv9q+CYtodLubNkEFdIURgk+AHXC7NojVF5A6NZ3x6jL/LEUIIn5LgB/67t5r91c0yhVMIERQk+IEFqwpJiAxlzqQh/i5FCCF8LuiDv7y+lc92VHDttCzCLLLZihAi8AV98L++pggNfG+6bLYihAgOQR38HQ4Xr68r5twxKWQlRPi7HCGE6BdBHfzLth+kqrFdBnWFEEElqIN/4epCshKsnDU62d+lCCFEvwna4N9d0cjqfbVcP2MoZpOsyyOECB5BG/wLVxcSajFxTZ5stiKECC5BGfzN7Q7eWV/KxZPSSIgM9Xc5QgjRr4Iy+N/fWEpTu4N5MqgrhAhCQRf8WmsWrCpkfFoMU7Pj/F2OEEL0u6AL/vVFNnYebGT+abLZihAiOAVd8C9YVUh0mIXLT033dylCCOEXQRX81U3tLNlykKtyM4kItfi7HCGE8IugCv638ovpcLqYN1PW5RFCBK+gCX6nS/PamiJOG57IyJRof5cjhBB+EzTB/+U3lZTYWpl/mkzhFEIEt6AJ/gWrCkmJDmP2+FR/lyKEEH4VFMFfXNvCim+quG56NiHmoPiRhRDiqIIiBRetKcKkFN+dLuvyCCFEwAd/m93JW/nFzB6XSlqs1d/lCCGE3wV88H+8tZza5g4Z1BVCCLeAD/4FqwoZnhTJ6SMS/V2KEEIMCAEd/NvK6llfVMf1M2VdHiGE6BTQwb9wdRHhISaunprp71KEEGLA8HnwK6XMSqkNSqnF7vvDlFJrlFJ7lFJvKqV8thNKdkIEN54xjNiIEF+9hBBCDDr90eK/A9jR7f5jwJ+01iMBG3CTr174J+eM4J6Lxvrq8kIIMSj5NPiVUpnAxcCL7vsKOA942/2QV4ErfFmDEEKInnzd4v8zcDfgct9PBOq01g73/RIg40hPVErdopTKV0rlV1VV+bhMIYQIHj4LfqXUJUCl1rrgRJ6vtX5Ba52ntc5LTk72cnVCCBG8fLkbyRnAZUqpuUA4EAM8DcQppSzuVn8mUOrDGoQQQvTisxa/1vrXWutMrXUOcB3wudb6euAL4Gr3w24APvBVDUIIIQ7nj3n89wC/UErtwejzf8kPNQghRNDql41ntdYrgBXu433A9P54XSGEEIcL6E/uCiGEOJzSWvu7huNSSlUBhf6u4yQlAdX+LmKAkN9FT/L76El+H4ec7O9iqNb6sGmRgyL4A4FSKl9rnefvOgYC+V30JL+PnuT3cYivfhfS1SOEEEFGgl8IIYKMBH//ecHfBQwg8rvoSX4fPcnv4xCf/C6kj18IIYKMtPiFECLISPALIUSQkeD3IaVUllLqC6XUdqXUNqXUHf6uaSDovStbMFNKxSml3lZK7VRK7VBKnebvmvxFKfVz9/+TrUqp15VS4f6uqT8ppV5WSlUqpbZ2O5eglPpUKbXbfRvvjdeS4PctB/BLrfV4YCZwq1JqvJ9rGgh678oWzJ4GlmqtxwKTCdLfi1IqA7gdyNNaTwTMGIs7BpN/ABf1OncvsFxrPQpY7r5/0iT4fUhrXa61Xu8+bsT4T33EjWeCRe9d2YKZUioWOAv3QoVa6w6tdZ1fi/IvC2BVSlmACKDMz/X0K631SqC21+nLMXYqBC/uWCjB30+UUjnAFGCNn0vxtz/Tc1e2YDYMqAJecXd9vaiUivR3Uf6gtS4FngCKgHKgXmu9zL9VDQipWuty9/FBINUbF5Xg7wdKqSjgHeBOrXWDv+vxl5PdlS0AWYCpwPNa6ylAM176U36wcfddX47xZpgORCql5vm3qoFFG3PvvTL/XoLfx5RSIRihv0hr/a6/6/Gzzl3ZDgBvAOcppRb6tyS/KgFKtNadfwW+jfFGEIzOB/Zrrau01nbgXeB0P9c0EFQopdIA3LeV3rioBL8PKaUURv/tDq31U/6ux9+Ositb0LbqtNYHgWKl1Bj3qVnAdj+W5E9FwEylVIT7/80sgnSgu5cPMXYqBC/uWCjB71tnAPMxWrYb3V9z/V2UGFBuAxYppTYDpwIP+7cc/3D/1fM2sB7YgpFNQbV0g1LqdWAVMEYpVaKUugl4FJitlNqN8VfRo155LVmyQQghgou0+IUQIshI8AshRJCR4BdCiCAjwS+EEEFGgl8IIYKMBL8IWkopZ7dpthuVUl771KxSKqf7KotCDCQWfxcghB+1aq1P9XcRQvQ3afEL0YtS6oBS6nGl1Bal1Fql1Ej3+Ryl1OdKqc1KqeVKqWz3+VSl1HtKqU3ur86lBsxKqb+715hfppSyuh9/u3uPhs1KqTf89GOKICbBL4KZtVdXz7XdvlevtZ4EPIuxoijAX4BXtdanAIuAZ9znnwG+1FpPxlhrZ5v7/CjgOa31BKAOuMp9/l5givs6P/bNjybE0cknd0XQUko1aa2jjnD+AHCe1nqfe5G9g1rrRKVUNZCmtba7z5drrZOUUlVApta6vds1coBP3RtooJS6BwjRWv+vUmop0AS8D7yvtW7y8Y8qRA/S4hfiyPRRjvuivduxk0NjahcDz2H8dbDOvfGIEP1Ggl+II7u22+0q9/HXHNoO8HrgK/fxcuAn0LWfcOzRLqqUMgFZWusvgHuAWOCwvzqE8CVpaYhgZlVKbex2f6nWunNKZ7x7xcx24Lvuc7dh7JZ1F8bOWTe6z98BvOBeTdGJ8SZQzpGZgYXuNwcFPBPk2y0KP5A+fiF6cffx52mtq/1dixC+IF09QggRZKTFL4QQQUZa/EIIEWQk+IUQIshI8AshRJCR4BdCiCAjwS+EEEHm/wPoXKjA8CW5NwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results.get_best_result().config)\n",
    "\n",
    "ax = None\n",
    "dfs = {result.log_dir: result.metrics_dataframe for result in results}\n",
    "for d in dfs.values():\n",
    "    ax = d.plot(ax=ax, y=\"mean_accuracy\", x=\"epoch\", legend=False)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Mean accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization (ASAH Scheduler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to make the example slightly harder by integrating the ASAH scheduler. This scheduler will try to stop non-promising trials in order to save ressources. This allows us to choose a higher number of samples without increasing the training time. \n",
    "\n",
    "We can reuse the train_tune() function and the config from before. Afterwards we need to define the scheduler with the correct arguments. \n",
    "\n",
    "Now we only need to add the scheduler to the TuneConfig and afterwards we can start the HPO.\n",
    "\n",
    "**HINT**: The ASAH scheduler can also take \"metric\" and \"mode\" as input. If you already defined this in the TuneConfig do **NOT** redefine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 18:09:12,195\tWARNING worker.py:1851 -- Warning: The actor ImplicitFunc is very large (45 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "2023-01-24 18:09:12,335\tWARNING util.py:244 -- The `start_trial` operation took 0.890 s, which may be a performance bottleneck.\n",
      "2023-01-24 18:09:17,382\tWARNING util.py:244 -- The `start_trial` operation took 0.514 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div class=\"trialProgress\">\n  <h3>Trial Progress</h3>\n  <table>\n<thead>\n<tr><th>Trial name            </th><th>date               </th><th>done  </th><th>episodes_total  </th><th style=\"text-align: right;\">  epoch</th><th>experiment_id                   </th><th>hostname          </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mean_accuracy</th><th>node_ip       </th><th style=\"text-align: right;\">   pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n</thead>\n<tbody>\n<tr><td>train_tune_d0083_00000</td><td>2023-01-24_18-09-25</td><td>False </td><td>                </td><td style=\"text-align: right;\">      1</td><td>275040c86b2b4b2b904404ecb2651124</td><td>raphael-20ujs00k00</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">        65.8333</td><td>192.168.188.20</td><td style=\"text-align: right;\">323289</td><td style=\"text-align: right;\">             10.9536</td><td style=\"text-align: right;\">           10.9536</td><td style=\"text-align: right;\">       10.9536</td><td style=\"text-align: right;\"> 1674580165</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>d0083_00000</td><td style=\"text-align: right;\">   0.00317645</td></tr>\n</tbody>\n</table>\n</div>\n<style>\n.trialProgress {\n  display: flex;\n  flex-direction: column;\n  color: var(--jp-ui-font-color1);\n}\n.trialProgress h3 {\n  font-weight: bold;\n}\n.trialProgress td {\n  white-space: nowrap;\n}\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 18:09:30,452\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-01-24 18:09:30,750\tERROR tune.py:758 -- Trials did not complete: [train_tune_d0083_00000, train_tune_d0083_00001, train_tune_d0083_00002, train_tune_d0083_00003, train_tune_d0083_00004, train_tune_d0083_00005, train_tune_d0083_00006, train_tune_d0083_00007]\n",
      "2023-01-24 18:09:30,751\tINFO tune.py:762 -- Total run time: 23.60 seconds (22.74 seconds for the tuning loop).\n",
      "2023-01-24 18:09:30,752\tWARNING tune.py:768 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    }
   ],
   "source": [
    "# Define the ASAH scheduler\n",
    "scheduler = ASHAScheduler(\n",
    "    max_t=config[\"epochs\"], # Max time per trial\n",
    "    time_attr=\"training_iteration\", # Which metric is used as measurement for \"time\"\n",
    "    grace_period=3\n",
    "    )\n",
    "\n",
    "# Create the HPO tuner\n",
    "tuner = tune.Tuner(\n",
    "    trainable,\n",
    "    param_space = config,\n",
    "    tune_config = tune.TuneConfig(\n",
    "        metric = \"mean_accuracy\",\n",
    "        mode = \"max\",\n",
    "        num_samples = 8,\n",
    "        scheduler=scheduler,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Start the tuner\n",
    "results_asah = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 10, 'lr': 0.03038005155333598, 'weight_decay': 0.004473015432021882}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m dfs \u001B[38;5;241m=\u001B[39m {result\u001B[38;5;241m.\u001B[39mlog_dir: result\u001B[38;5;241m.\u001B[39mmetrics_dataframe \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m results_asah}\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m dfs\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m----> 6\u001B[0m     ax \u001B[38;5;241m=\u001B[39m \u001B[43md\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m(ax\u001B[38;5;241m=\u001B[39max, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean_accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m, x\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m, legend\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      7\u001B[0m ax\u001B[38;5;241m.\u001B[39mset_xlabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpochs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      8\u001B[0m ax\u001B[38;5;241m.\u001B[39mset_ylabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMean accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'plot'"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results_asah.get_best_result().config)\n",
    "\n",
    "ax = None\n",
    "dfs = {result.log_dir: result.metrics_dataframe for result in results_asah}\n",
    "for d in dfs.values():\n",
    "    ax = d.plot(ax=ax, y=\"mean_accuracy\", x=\"epoch\", legend=False)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Mean accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph we can see that indeed trials were stopped by ASAH."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization (PBT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tune_pbt_600px.png](images/tune_pbt_600px.png)\n",
    "\n",
    "*Ray Framework Overview (https://docs.ray.io/en/latest/index.html)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most interesting HPO algorithms in Ray Tune is the Population Based Training (PBT). In PBT we do not see each trial as independent but we rather try to increase the performance of the whole population of trials. After some epochs PBT will replace bad performing trials with good performing ones and perturb their parameters. Similar to the ASAH scheduler this will ensure that non-promising trials are stopped early on and that the search focuses on the promising parts in the search space. \n",
    "\n",
    "Ray Tune contains a distributed implementation of this algorithm. Since PBT will replace the bad with the good trials we need to somehow store the state of the good trials. This can be achieved by using checkpoints in Ray. The code below shows the modified train_tune() function.\n",
    "\n",
    "Let's first look at the added lines in the training loop. We can directly create a checkpoint from a dictionary (storing the models parameters and the epochs) by using the Checkpoint.from_dict() function. This checkpoint can be added to session.report(). Now a checkpoint containing the model's state will be created in each iteration. For large epoch number the checkpoint frequency should be lower to avoid unnecessary overhead.\n",
    "\n",
    "If a bad trial is stopped Tune will create a new trial and run the training function with the perturbed hyperparameters. It will furthermore copy the checkpoint of the better performing trial. Therefore we need to check whether a checkpoint is available at the beginning of the training. If there is no checkpoint available we now that this trial is new and was not replace. If there is a checkpoint available then the trial was replaced and we need to load the state of the model. Furthermore we need to set the current epoch to the correct value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune_pbt(config):\n",
    "    step = 0\n",
    "    epochs = config[\"epochs\"]\n",
    "    lr = config[\"lr\"]\n",
    "    weight_decay = config[\"weight_decay\"]\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = NeuralNetwork().to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    if session.get_checkpoint():\n",
    "        loaded_checkpoint = session.get_checkpoint()\n",
    "        checkpoint = loaded_checkpoint.to_dict()\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        step = checkpoint[\"last_step\"] + 1\n",
    "\n",
    "    for t in range(step, epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy = test(val_dataloader, model, loss_fn, device)\n",
    "\n",
    "        checkpoint = Checkpoint.from_dict(\n",
    "            {\n",
    "                \"last_step\": t,\n",
    "                \"model_state\": model.state_dict(),\n",
    "            }\n",
    "        )\n",
    "        session.report(metrics={\"mean_accuracy\": accuracy, \"step\": t}, checkpoint=checkpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the process is similar to the examples before. We create a trainable function and assign the needed ressources. Instead of defining the ASAH scheduler as before we define the PBT scheduler and the tuner is created and started as done before.\n",
    "\n",
    "**HINT**: The PBT scheduler can also take \"metric\" and \"mode\" as input. If you already defined this in the TuneConfig do **NOT** redefine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define resources for each trial\n",
    "resources = {\"cpu\":2, \"gpu\":1} if torch.cuda.is_available() else {\"cpu\":2}\n",
    "trainable = tune.with_resources(train_tune_pbt, resources=resources) \n",
    "\n",
    "# Define the PBT algorithm\n",
    "scheduler = PopulationBasedTraining(\n",
    "    time_attr = \"training_iteration\",\n",
    "    perturbation_interval = 2,\n",
    "    hyperparam_mutations = {\n",
    "        \"lr\": config[\"lr\"],\n",
    "        \"weight_decay\": config[\"weight_decay\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "# Create the HPO tuner\n",
    "tuner = tune.Tuner(\n",
    "    trainable,\n",
    "    param_space = config,\n",
    "    tune_config = tune.TuneConfig(\n",
    "        metric = \"mean_accuracy\",\n",
    "        mode = \"max\",\n",
    "        num_samples = 4,\n",
    "        scheduler=scheduler,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Run the tuner\n",
    "results_pbt = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_pbt.get_best_result().config)\n",
    "\n",
    "ax = None\n",
    "dfs = {result.log_dir: result.metrics_dataframe for result in results_pbt}\n",
    "for d in dfs.values():\n",
    "    ax = d.plot(ax=ax, y=\"mean_accuracy\", x=\"step\", legend=False)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Mean accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ray_tune",
   "language": "python",
   "display_name": "Ray_Tune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "12b5708e47bcce2ed9c7c0871afac25011cce35a7f95a435508fd0065dc55843"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
